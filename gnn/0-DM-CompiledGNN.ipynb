{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Onnx GNN Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "libcublas.so.11: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5a316ce48ece>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclear_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0monnxruntime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx/lib/python3.8/site-packages/onnxruntime/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_dll_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcuda_bin_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0monnxruntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pybind_state\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_all_providers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_available_providers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mRunOptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSessionOptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_default_logger_severity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_telemetry_events\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable_telemetry_events\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mNodeArg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelMetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGraphOptimizationLevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExecutionMode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExecutionOrder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOrtDevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSessionIOBinding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx/lib/python3.8/site-packages/onnxruntime/capi/_pybind_state.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplatform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0monnxruntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ld_preload\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx/lib/python3.8/site-packages/onnxruntime/capi/_ld_preload.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# LD_PRELOAD_BEGIN_MARK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mctypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCDLL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRTLD_GLOBAL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0m_libcublas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"libcublas.so.11\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRTLD_GLOBAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0m_libcudnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"libcudnn.so.8\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRTLD_GLOBAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0m_libcurand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"libcurand.so.10\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRTLD_GLOBAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx/lib/python3.8/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: libcublas.so.11: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "# System imports\n",
    "import os\n",
    "import sys\n",
    "import collections.abc as container_abcs\n",
    "from pprint import pprint as pp\n",
    "from time import time as tt\n",
    "\n",
    "# External imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch.nn as nn\n",
    "# from torch_scatter import scatter_add\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import HTML, display\n",
    "import onnxruntime\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Get rid of RuntimeWarnings, gross\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# from gnn.checkpoint_agnn import CheckpointedResAGNN\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir= \"/global/cscratch1/sd/danieltm/ExaTrkX/trackml-codalab/embedding_processed/1_pt_cut_endcaps_unweighted_augmented/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_events = 10\n",
    "all_events = os.listdir(input_dir)\n",
    "loaded_events = [torch.load(os.path.join(input_dir,event)) for event in all_events[:num_events]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mlp(\n",
    "    input_size,\n",
    "    sizes,\n",
    "    hidden_activation=\"ReLU\",\n",
    "    output_activation=\"ReLU\",\n",
    "    layer_norm=False,\n",
    "):\n",
    "    \"\"\"Construct an MLP with specified fully-connected layers.\"\"\"\n",
    "    hidden_activation = getattr(nn, hidden_activation)\n",
    "    if output_activation is not None:\n",
    "        output_activation = getattr(nn, output_activation)\n",
    "    layers = []\n",
    "    n_layers = len(sizes)\n",
    "    sizes = [input_size] + sizes\n",
    "    # Hidden layers\n",
    "    for i in range(n_layers - 1):\n",
    "        layers.append(nn.Linear(sizes[i], sizes[i + 1]))\n",
    "        if layer_norm:\n",
    "            layers.append(nn.LayerNorm(sizes[i + 1]))\n",
    "        layers.append(hidden_activation())\n",
    "    # Final layer\n",
    "    layers.append(nn.Linear(sizes[-2], sizes[-1]))\n",
    "    if output_activation is not None:\n",
    "        if layer_norm:\n",
    "            layers.append(nn.LayerNorm(sizes[-1]))\n",
    "        layers.append(output_activation())\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_add_attention(encoded_nodes, encoded_edges, edge_list):\n",
    "    start, end = edge_list[0], edge_list[1]\n",
    "\n",
    "    src = encoded_nodes[end]*encoded_edges\n",
    "    index = start.unsqueeze(-1)\n",
    "    in_messages = torch.zeros(encoded_nodes.shape, dtype=src.dtype, device=encoded_nodes.device).scatter_add(0, index.repeat((1,src.shape[1])), src) \n",
    "\n",
    "    src = encoded_nodes[start]*encoded_edges\n",
    "    index = end.unsqueeze(-1)\n",
    "    out_messages = torch.zeros(encoded_nodes.shape, dtype=src.dtype, device=encoded_nodes.device).scatter_add(0, index.repeat((1,src.shape[1])), src) \n",
    "    \n",
    "    aggr_nodes = in_messages + out_messages\n",
    "    \n",
    "    return aggr_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class ResAGNN(nn.Module):\n",
    "    def __init__(self, hparams):\n",
    "        super(ResAGNN, self).__init__()\n",
    "        \"\"\"\n",
    "        Initialise the Lightning Module that can scan over different GNN training regimes\n",
    "        \"\"\"\n",
    "        \n",
    "        self.hparams = hparams\n",
    "        \n",
    "        # Setup input network\n",
    "        self.node_encoder = make_mlp(\n",
    "            hparams[\"in_channels\"],\n",
    "            [hparams[\"hidden\"]],\n",
    "            output_activation=hparams[\"hidden_activation\"],\n",
    "            layer_norm=hparams[\"layernorm\"],\n",
    "        )\n",
    "\n",
    "        # The edge network computes new edge features from connected nodes\n",
    "        self.edge_network = make_mlp(\n",
    "            2 * (hparams[\"in_channels\"] + hparams[\"hidden\"]),\n",
    "            [hparams[\"hidden\"]] * hparams[\"nb_edge_layer\"] + [1],\n",
    "            layer_norm=hparams[\"layernorm\"],\n",
    "            output_activation=None,\n",
    "            hidden_activation=hparams[\"hidden_activation\"],\n",
    "        )\n",
    "\n",
    "        # The node network computes new node features\n",
    "        self.node_network = make_mlp(\n",
    "            (hparams[\"in_channels\"] + hparams[\"hidden\"]) * 2,\n",
    "            [hparams[\"hidden\"]] * hparams[\"nb_node_layer\"],\n",
    "            layer_norm=hparams[\"layernorm\"],\n",
    "            output_activation=None,\n",
    "            hidden_activation=hparams[\"hidden_activation\"],\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        # Encode the graph features into the hidden space\n",
    "        input_x = x\n",
    "        x = self.node_encoder(x)\n",
    "        x = torch.cat([x, input_x], dim=-1)\n",
    "\n",
    "        start, end = edge_index[0], edge_index[1]\n",
    "\n",
    "        # Loop over iterations of edge and node networks\n",
    "        for i in range(self.hparams[\"n_graph_iters\"]):\n",
    "            # Previous hidden state\n",
    "            x0 = x\n",
    "\n",
    "            # Compute new edge score\n",
    "            edge_inputs = torch.cat([x[start], x[end]], dim=1)\n",
    "            e = self.edge_network(edge_inputs)\n",
    "            e = torch.sigmoid(e)\n",
    "\n",
    "            # Sum weighted node features coming into each node\n",
    "            #             weighted_messages_in = scatter_add(e * x[start], end, dim=0, dim_size=x.shape[0])\n",
    "            #             weighted_messages_out = scatter_add(e * x[end], start, dim=0, dim_size=x.shape[0])\n",
    "\n",
    "            weighted_messages = scatter_add_attention(x, e, edge_index)\n",
    "\n",
    "            # Compute new node features\n",
    "            #             node_inputs = torch.cat([x, weighted_messages_in, weighted_messages_out], dim=1)\n",
    "            node_inputs = torch.cat([x, weighted_messages], dim=1)\n",
    "            x = self.node_network(node_inputs)\n",
    "\n",
    "            # Residual connection\n",
    "            x = torch.cat([x, input_x], dim=-1)\n",
    "            x = x + x0\n",
    "\n",
    "        # Compute final edge scores; use original edge directions only\n",
    "        clf_inputs = torch.cat([x[start], x[end]], dim=1)\n",
    "        return self.edge_network(clf_inputs).squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore this testing model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class ResAGNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResAGNN, self).__init__()\n",
    "        \"\"\"\n",
    "        Initialise the Lightning Module that can scan over different GNN training regimes\n",
    "        \"\"\"\n",
    "        print(\"init\")\n",
    "        \n",
    "\n",
    "        self.test_network =  torch.nn.Sequential(\n",
    "                                torch.nn.Linear(3, 64),\n",
    "                                torch.nn.ReLU(),\n",
    "                                torch.nn.Linear(64, 1),\n",
    "                            )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Encode the graph features into the hidden space\n",
    "        #         input_x = x\n",
    "        new_x = self.test_network(x)\n",
    "        #         x = torch.cat([x, input_x], dim=1)\n",
    "\n",
    "        #         start, end = edge_index[0], edge_index[1]\n",
    "\n",
    "        return new_x\n",
    "        \n",
    "    \n",
    "        # Loop over iterations of edge and node networks\n",
    "#         for i in range(8):\n",
    "#             # Previous hidden state\n",
    "#             x0 = x\n",
    "\n",
    "#             # Compute new edge score\n",
    "#             edge_inputs = torch.cat([x[start], x[end]], dim=1)\n",
    "        \n",
    "        \n",
    "#             e = self.edge_network(edge_inputs)\n",
    "#             e = torch.sigmoid(e)\n",
    "\n",
    "        \n",
    "#             # Sum weighted node features coming into each node\n",
    "#             #             weighted_messages_in = scatter_add(e * x[start], end, dim=0, dim_size=x.shape[0])\n",
    "#             #             weighted_messages_out = scatter_add(e * x[end], start, dim=0, dim_size=x.shape[0])\n",
    "\n",
    "#             weighted_messages = scatter_add_attention(x, e, edge_index)\n",
    "\n",
    "#             # Compute new node features\n",
    "#             #             node_inputs = torch.cat([x, weighted_messages_in, weighted_messages_out], dim=1)\n",
    "#             node_inputs = torch.cat([x, weighted_messages], dim=1)\n",
    "#             x = self.node_network(node_inputs)\n",
    "\n",
    "#             # Residual connection\n",
    "#             x = torch.cat([x, input_x], dim=-1)\n",
    "#             x = x + x0\n",
    "\n",
    "#         # Compute final edge scores; use original edge directions only\n",
    "#         clf_inputs = torch.cat([x[start], x[end]], dim=1)\n",
    "# return self.edge_network(clf_inputs).squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = checkpoint[\"hyper_parameters\"]\n",
    "state_dict = checkpoint[\"state_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(hparams, \"hyper_parameters.ckpt\")\n",
    "torch.save(state_dict, \"state_dict.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = torch.load(\"hyper_parameters.ckpt\")\n",
    "state_dict = torch.load(\"state_dict.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResAGNN(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data = loaded_events[0]\n",
    "input_data = (example_data.x, example_data.edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onnx Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONNX_FILE_PATH = \"ResAGNN_model.onnx\"\n",
    "dynamic_axes = {\"nodes\": [0, 1], \"edge_index\": [0, 1]}\n",
    "torch.onnx.export(model, input_data, ONNX_FILE_PATH, input_names=[\"nodes\", \"edge_index\"], opset_version=12,\n",
    "                  output_names=[\"output\"], export_params=True, dynamic_axes=dynamic_axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = onnxruntime.InferenceSession(ONNX_FILE_PATH, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_list = [(event.x, event.edge_index) for event in loaded_events]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VOILA!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.9123555, -0.6301682,  0.9521093, ...,  4.3359084,  3.2423496,\n",
       "        1.5909792], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(None, {\"nodes\": input_data_list[0][0].numpy(), \"edge_index\": input_data_list[0][1].numpy()})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.91810256, -3.100629  , -0.5200292 , ..., -2.6808546 ,\n",
       "        4.421003  ,  4.1069803 ], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(None, {\"nodes\": input_data_list[1][0].numpy(), \"edge_index\": input_data_list[1][1].numpy()})[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torchscript Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_script_module = torch.jit.trace(model, input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2641, -0.2798, -0.2481,  ..., -0.4477, -0.0890, -0.5004],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_script_module(input_data[0], input_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n"
     ]
    }
   ],
   "source": [
    "script_module = torch.jit.script(ResAGNN())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out= script_module(input_data[0], input_data[1])\n",
    "out= script_module(input_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1020],\n",
       "        [ 0.1171],\n",
       "        [ 0.1397],\n",
       "        ...,\n",
       "        [ 0.3792],\n",
       "        [-0.0710],\n",
       "        [-0.0020]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%nodes : Float(*, *, strides=[3, 1], requires_grad=0, device=cpu),\n",
      "      %test_network.0.weight : Float(64, 3, strides=[3, 1], requires_grad=0, device=cpu),\n",
      "      %test_network.0.bias : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %test_network.2.weight : Float(1, 64, strides=[64, 1], requires_grad=0, device=cpu),\n",
      "      %test_network.2.bias : Float(1, strides=[1], requires_grad=0, device=cpu)):\n",
      "  %5 : Float(*, 64, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%nodes, %test_network.0.weight, %test_network.0.bias) # /global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/torch/nn/functional.py:1847:11\n",
      "  %6 : Float(*, 64, device=cpu) = onnx::Relu(%5) # /global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/torch/nn/functional.py:1298:17\n",
      "  %7 : Float(*, 1, strides=[1, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%6, %test_network.2.weight, %test_network.2.bias) # /global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/torch/nn/functional.py:1847:11\n",
      "  return (%7)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/torch/onnx/utils.py:1192: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input nodes\n",
      "  'Automatically generated names will be applied to each dynamic axes of input {}'.format(key))\n"
     ]
    }
   ],
   "source": [
    "ONNX_FILE_PATH = \"ResAGNN_script_model.onnx\"\n",
    "dynamic_axes = {\"nodes\": [0, 1]}\n",
    "# torch.onnx.export(script_module, input_data, ONNX_FILE_PATH, input_names=[\"nodes\", \"edge_index\"],  opset_version=12,\n",
    "torch.onnx.export(script_module, input_data[0], ONNX_FILE_PATH, input_names=[\"nodes\"],  opset_version=12, verbose=True,\n",
    "                  export_params=True, example_outputs=out, dynamic_axes=dynamic_axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONNX_FILE_PATH = \"ResAGNN_script_model.onnx\"\n",
    "session = onnxruntime.InferenceSession(ONNX_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_list = [(event.x, event.edge_index) for event in loaded_events]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nodes'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.get_inputs()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10199904],\n",
       "       [ 0.11714503],\n",
       "       [ 0.13971089],\n",
       "       ...,\n",
       "       [ 0.37922925],\n",
       "       [-0.07096032],\n",
       "       [-0.00202517]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(None, {\"nodes\": input_data_list[0][0].numpy()})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.12115289],\n",
       "       [ 0.06801388],\n",
       "       [ 0.12111214],\n",
       "       ...,\n",
       "       [-0.06109324],\n",
       "       [-0.06108928],\n",
       "       [ 0.10260198]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(None, {\"nodes\": input_data_list[1][0].numpy()})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Invalid Feed Input Name:nodes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-4699c2d97b29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"nodes\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_data_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"edge_index\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_data_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_meta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPFail\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Invalid Feed Input Name:nodes"
     ]
    }
   ],
   "source": [
    "session.run(None, {\"nodes\": input_data_list[0][0].numpy(), \"edge_index\": input_data_list[0][1].numpy()})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Invalid Feed Input Name:nodes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-a89730cd3efd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"nodes\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_data_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"edge_index\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_data_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_meta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPFail\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Invalid Feed Input Name:nodes"
     ]
    }
   ],
   "source": [
    "session.run(None, {\"nodes\": input_data_list[1][0].numpy(), \"edge_index\": input_data_list[1][1].numpy()})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exatrkx [~/.conda/envs/exatrkx/]",
   "language": "python",
   "name": "conda_exatrkx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
